{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sumaiyakawsar/NLP_Masters_Class/blob/main/Lab3_Text_Normalization_Stemming_and_Lemmatization.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wzGBvgsEmOuI"
      },
      "source": [
        "# Stem vs. Lemma vs. Lexeme\n",
        "#### A lemma is a word that stands at the head of a definition in a dictionary. All the head words in a dictionary are lemmas.\n",
        "#### A lexeme is a unit of meaning, and can be more than one word. A lexeme is the set of all forms that have the same meaning.\n",
        "#### In computational linguistics, a stem is the part of the word that never changes even when different forms of the word are used."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CBeWR7aBmOuc"
      },
      "source": [
        "## Stemmers --> PorterStemmer"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('punkt')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zzs9A3RCxTxc",
        "outputId": "a5469574-8b3a-4607-c03b-c92192f2e418"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xPiZEv0OmOuo",
        "outputId": "3ab0c8fa-7529-4752-9ca6-79768bf778cf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from nltk.stem import PorterStemmer\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "ps = PorterStemmer()\n",
        "\n",
        "new_text = \"\"\"It is very important to be pythonly while you are pythoning with python.\n",
        "              All pythoners have pythoned poorly at least once.\"\"\"\n",
        "\n",
        "words = word_tokenize(new_text)\n",
        "\n",
        "print([ps.stem(w) for w in words])"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['it', 'is', 'veri', 'import', 'to', 'be', 'pythonli', 'while', 'you', 'are', 'python', 'with', 'python', '.', 'all', 'python', 'have', 'python', 'poorli', 'at', 'least', 'onc', '.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xRHJmSHZmOur"
      },
      "source": [
        "## Stemmers --> LancasterStemmer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WtAlJtUXmOus",
        "outputId": "7bb738f2-3b57-4e68-fc8f-e56d43fb1223",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from nltk.stem import PorterStemmer, LancasterStemmer\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "raw = \"\"\"DENNIS: Listen, strange women lying in ponds distributing swords\n",
        "    is no basis for a system of government.  Supreme executive power derives from\n",
        "    a mandate from the masses, not from some farcical aquatic ceremony.\"\"\"\n",
        "\n",
        "tokens = word_tokenize(raw)\n",
        "\n",
        "porter = PorterStemmer()\n",
        "lancaster = LancasterStemmer()\n",
        "\n",
        "print([porter.stem(t) for t in tokens])\n",
        "print(\"\\n\")\n",
        "print([lancaster.stem(t) for t in tokens])\n"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['denni', ':', 'listen', ',', 'strang', 'women', 'lie', 'in', 'pond', 'distribut', 'sword', 'is', 'no', 'basi', 'for', 'a', 'system', 'of', 'govern', '.', 'suprem', 'execut', 'power', 'deriv', 'from', 'a', 'mandat', 'from', 'the', 'mass', ',', 'not', 'from', 'some', 'farcic', 'aquat', 'ceremoni', '.']\n",
            "\n",
            "\n",
            "['den', ':', 'list', ',', 'strange', 'wom', 'lying', 'in', 'pond', 'distribut', 'sword', 'is', 'no', 'bas', 'for', 'a', 'system', 'of', 'govern', '.', 'suprem', 'execut', 'pow', 'der', 'from', 'a', 'mand', 'from', 'the', 'mass', ',', 'not', 'from', 'som', 'farc', 'aqu', 'ceremony', '.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yW7h3s9mmOuv"
      },
      "source": [
        "## Lemmatization --> WordNetLemmatizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9ZJfV0xsmOux",
        "outputId": "dadc9f95-c383-4781-cb4f-7bbcb521bc63"
      },
      "source": [
        "from nltk.stem import WordNetLemmatizer, PorterStemmer\n",
        "nltk.download('wordnet')\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "print(\"rocks :\", lemmatizer.lemmatize(\"rocks\"))\n",
        "print(\"\\nproduced :\", lemmatizer.lemmatize(\"produced\", pos = 'v'))\n",
        "\n",
        "ps = PorterStemmer()\n",
        "print(\"\\nStem of the word produced :\", ps.stem(\"produced\"))\n",
        "\n",
        "print(\"\\nbetter :\", lemmatizer.lemmatize(\"better\", pos =\"a\"))\n",
        "\n",
        "print(\"\\nwomen :\", lemmatizer.lemmatize(\"women\", pos =\"n\"))"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "rocks : rock\n",
            "\n",
            "produced : produce\n",
            "\n",
            "Stem of the word produced : produc\n",
            "\n",
            "better : good\n",
            "\n",
            "women : woman\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U1jNoCT9mOu2",
        "outputId": "bf3d1c27-7f3c-4262-98e0-452d9ff15d29"
      },
      "source": [
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "raw = \"\"\"DENNIS: Listen, strange women lying in ponds distributing swords\n",
        "    is no basis for a system of government.  Supreme executive power derives from\n",
        "    a mandate from the masses, not from some farcical aquatic ceremony.\"\"\"\n",
        "\n",
        "tokens = word_tokenize(raw)\n",
        "\n",
        "wnl = WordNetLemmatizer()\n",
        "print([wnl.lemmatize(t) for t in tokens])\n",
        "print()\n",
        "\n",
        "for t in tokens:\n",
        "    print (\"{0:20}{1:20}\".format(t, wnl.lemmatize(t, pos=\"v\")))\n",
        "print()\n",
        "example_words = [\"List\", \"listed\", \"lists\", \"listing\", \"listings\"]\n",
        "print([wnl.lemmatize(w) for w in example_words])\n",
        "print()\n",
        "for words in example_words:\n",
        "    print (\"{0:20}{1:20}\".format(words, wnl.lemmatize(words, pos=\"v\")))"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['DENNIS', ':', 'Listen', ',', 'strange', 'woman', 'lying', 'in', 'pond', 'distributing', 'sword', 'is', 'no', 'basis', 'for', 'a', 'system', 'of', 'government', '.', 'Supreme', 'executive', 'power', 'derives', 'from', 'a', 'mandate', 'from', 'the', 'mass', ',', 'not', 'from', 'some', 'farcical', 'aquatic', 'ceremony', '.']\n",
            "\n",
            "DENNIS              DENNIS              \n",
            ":                   :                   \n",
            "Listen              Listen              \n",
            ",                   ,                   \n",
            "strange             strange             \n",
            "women               women               \n",
            "lying               lie                 \n",
            "in                  in                  \n",
            "ponds               ponds               \n",
            "distributing        distribute          \n",
            "swords              swords              \n",
            "is                  be                  \n",
            "no                  no                  \n",
            "basis               basis               \n",
            "for                 for                 \n",
            "a                   a                   \n",
            "system              system              \n",
            "of                  of                  \n",
            "government          government          \n",
            ".                   .                   \n",
            "Supreme             Supreme             \n",
            "executive           executive           \n",
            "power               power               \n",
            "derives             derive              \n",
            "from                from                \n",
            "a                   a                   \n",
            "mandate             mandate             \n",
            "from                from                \n",
            "the                 the                 \n",
            "masses              mass                \n",
            ",                   ,                   \n",
            "not                 not                 \n",
            "from                from                \n",
            "some                some                \n",
            "farcical            farcical            \n",
            "aquatic             aquatic             \n",
            "ceremony            ceremony            \n",
            ".                   .                   \n",
            "\n",
            "['List', 'listed', 'list', 'listing', 'listing']\n",
            "\n",
            "List                List                \n",
            "listed              list                \n",
            "lists               list                \n",
            "listing             list                \n",
            "listings            list                \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3DPjJ4YZmOu4"
      },
      "source": [
        "# Lemmatization using TextBlob"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d47Ou3jwmOu5",
        "outputId": "d5f5d986-c485-4206-d8a8-57ac0608f541"
      },
      "source": [
        "from textblob import TextBlob\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "wnl = WordNetLemmatizer()\n",
        "nltk.download('wordnet')\n",
        "\n",
        "sentence = TextBlob('DENNIS: Listen, strange women lying in ponds distributing swords is no basis for a system of government. Supreme executive power derives from a mandate from the masses, not from some farcical aquatic ceremony.')\n",
        "tokens = sentence.words\n",
        "print(tokens)\n",
        "print()\n",
        "print(tokens.lemmatize())\n",
        "print()\n",
        "\n",
        "for t in tokens:\n",
        "    print (\"{0:20}{1:20}\".format(t, wnl.lemmatize(t, pos=\"v\")))"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['DENNIS', 'Listen', 'strange', 'women', 'lying', 'in', 'ponds', 'distributing', 'swords', 'is', 'no', 'basis', 'for', 'a', 'system', 'of', 'government', 'Supreme', 'executive', 'power', 'derives', 'from', 'a', 'mandate', 'from', 'the', 'masses', 'not', 'from', 'some', 'farcical', 'aquatic', 'ceremony']\n",
            "\n",
            "['DENNIS', 'Listen', 'strange', 'woman', 'lying', 'in', 'pond', 'distributing', 'sword', 'is', 'no', 'basis', 'for', 'a', 'system', 'of', 'government', 'Supreme', 'executive', 'power', 'derives', 'from', 'a', 'mandate', 'from', 'the', 'mass', 'not', 'from', 'some', 'farcical', 'aquatic', 'ceremony']\n",
            "\n",
            "DENNIS              DENNIS              \n",
            "Listen              Listen              \n",
            "strange             strange             \n",
            "women               women               \n",
            "lying               lie                 \n",
            "in                  in                  \n",
            "ponds               ponds               \n",
            "distributing        distribute          \n",
            "swords              swords              \n",
            "is                  be                  \n",
            "no                  no                  \n",
            "basis               basis               \n",
            "for                 for                 \n",
            "a                   a                   \n",
            "system              system              \n",
            "of                  of                  \n",
            "government          government          \n",
            "Supreme             Supreme             \n",
            "executive           executive           \n",
            "power               power               \n",
            "derives             derive              \n",
            "from                from                \n",
            "a                   a                   \n",
            "mandate             mandate             \n",
            "from                from                \n",
            "the                 the                 \n",
            "masses              mass                \n",
            "not                 not                 \n",
            "from                from                \n",
            "some                some                \n",
            "farcical            farcical            \n",
            "aquatic             aquatic             \n",
            "ceremony            ceremony            \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9BlC0XFXmOu6",
        "outputId": "74ea7b46-bef2-4de3-ad03-0be0983ad762"
      },
      "source": [
        "from textblob import TextBlob\n",
        "text = TextBlob(\"List listed lists listing listings\")\n",
        "tokens = text.words\n",
        "print(tokens)\n",
        "print(\"\\n\",tokens.lemmatize())\n",
        "print()\n",
        "for t in tokens:\n",
        "    print (\"{0:20}{1:20}\".format(t, wnl.lemmatize(t, pos=\"v\")))"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['List', 'listed', 'lists', 'listing', 'listings']\n",
            "\n",
            " ['List', 'listed', 'list', 'listing', 'listing']\n",
            "\n",
            "List                List                \n",
            "listed              list                \n",
            "lists               list                \n",
            "listing             list                \n",
            "listings            list                \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TWjDRkRPmOu7"
      },
      "source": [
        "# Stemming & Lemmatization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LlpTiNJOmOu8"
      },
      "source": [
        "### Stemming and Lemmatization both generate the root form of the inflected words. The difference is that stem might not be an actual word whereas, lemma is an actual language word."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "odGmHicbmOu8",
        "outputId": "861182bd-80ef-4fb2-d120-e3b3666f94a4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "import nltk\n",
        "from nltk.stem import PorterStemmer\n",
        "from nltk.stem import LancasterStemmer\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.stem.snowball import SnowballStemmer\n",
        "\n",
        "raw = \"\"\"DENNIS: Listen, strange women lying in ponds distributing swords\n",
        "    is no basis for a system of government.  Supreme executive power derives from\n",
        "    a mandate from the masses, not from some farcical aquatic ceremony.\"\"\"\n",
        "\n",
        "words = raw.lower()\n",
        "print(words)\n",
        "print()\n",
        "tokens = word_tokenize(words)\n",
        "print(\"Tokens\")\n",
        "print(tokens)\n",
        "print()\n",
        "print(\"Lemmas\")\n",
        "wnl = nltk.WordNetLemmatizer()\n",
        "print([wnl.lemmatize(t, pos = \"v\") for t in tokens])\n",
        "print()\n",
        "print(\"Porter Stemming\")\n",
        "ps = PorterStemmer()\n",
        "print ([ps.stem(t) for t in tokens])\n",
        "print()\n",
        "print(\"Lancaster Stemming\")\n",
        "ls = LancasterStemmer()\n",
        "print ([ls.stem(t) for t in tokens])\n",
        "print()\n",
        "print(\"Snowball Stemming\")\n",
        "sn = nltk.SnowballStemmer(\"english\")\n",
        "print([sn.stem(t) for t in tokens])"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dennis: listen, strange women lying in ponds distributing swords\n",
            "    is no basis for a system of government.  supreme executive power derives from\n",
            "    a mandate from the masses, not from some farcical aquatic ceremony.\n",
            "\n",
            "Tokens\n",
            "['dennis', ':', 'listen', ',', 'strange', 'women', 'lying', 'in', 'ponds', 'distributing', 'swords', 'is', 'no', 'basis', 'for', 'a', 'system', 'of', 'government', '.', 'supreme', 'executive', 'power', 'derives', 'from', 'a', 'mandate', 'from', 'the', 'masses', ',', 'not', 'from', 'some', 'farcical', 'aquatic', 'ceremony', '.']\n",
            "\n",
            "Lemmas\n",
            "['dennis', ':', 'listen', ',', 'strange', 'women', 'lie', 'in', 'ponds', 'distribute', 'swords', 'be', 'no', 'basis', 'for', 'a', 'system', 'of', 'government', '.', 'supreme', 'executive', 'power', 'derive', 'from', 'a', 'mandate', 'from', 'the', 'mass', ',', 'not', 'from', 'some', 'farcical', 'aquatic', 'ceremony', '.']\n",
            "\n",
            "Porter Stemming\n",
            "['denni', ':', 'listen', ',', 'strang', 'women', 'lie', 'in', 'pond', 'distribut', 'sword', 'is', 'no', 'basi', 'for', 'a', 'system', 'of', 'govern', '.', 'suprem', 'execut', 'power', 'deriv', 'from', 'a', 'mandat', 'from', 'the', 'mass', ',', 'not', 'from', 'some', 'farcic', 'aquat', 'ceremoni', '.']\n",
            "\n",
            "Lancaster Stemming\n",
            "['den', ':', 'list', ',', 'strange', 'wom', 'lying', 'in', 'pond', 'distribut', 'sword', 'is', 'no', 'bas', 'for', 'a', 'system', 'of', 'govern', '.', 'suprem', 'execut', 'pow', 'der', 'from', 'a', 'mand', 'from', 'the', 'mass', ',', 'not', 'from', 'som', 'farc', 'aqu', 'ceremony', '.']\n",
            "\n",
            "Snowball Stemming\n",
            "['denni', ':', 'listen', ',', 'strang', 'women', 'lie', 'in', 'pond', 'distribut', 'sword', 'is', 'no', 'basi', 'for', 'a', 'system', 'of', 'govern', '.', 'suprem', 'execut', 'power', 'deriv', 'from', 'a', 'mandat', 'from', 'the', 'mass', ',', 'not', 'from', 'some', 'farcic', 'aquat', 'ceremoni', '.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0ATI6roEmOu_"
      },
      "source": [
        "# Stemmers --> SnowballStemmer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "amzF9MVCmOvG",
        "outputId": "69f705e4-5b9c-4159-c4a5-7de604f2b559"
      },
      "source": [
        "print(nltk.SnowballStemmer.languages)\n",
        "print(len(nltk.SnowballStemmer.languages))\n",
        "print()\n",
        "text = \"This is achieved in practice during stemming, a text preprocessing operation.\"\n",
        "tokens = nltk.tokenize.word_tokenize(text)\n",
        "print()\n",
        "stemmer = nltk.SnowballStemmer('english')\n",
        "print([stemmer.stem(t) for t in tokens])\n",
        "print()\n",
        "text2 = \"Ceci est réalisé en pratique lors du stemming, une opération de prétraitement de texte.\"\n",
        "tokens2 = nltk.tokenize.word_tokenize(text2)\n",
        "print()\n",
        "stemmer = nltk.SnowballStemmer('french')\n",
        "print([stemmer.stem(t) for t in tokens2])"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "('arabic', 'danish', 'dutch', 'english', 'finnish', 'french', 'german', 'hungarian', 'italian', 'norwegian', 'porter', 'portuguese', 'romanian', 'russian', 'spanish', 'swedish')\n",
            "16\n",
            "\n",
            "\n",
            "['this', 'is', 'achiev', 'in', 'practic', 'dure', 'stem', ',', 'a', 'text', 'preprocess', 'oper', '.']\n",
            "\n",
            "\n",
            "['cec', 'est', 'réalis', 'en', 'pratiqu', 'lor', 'du', 'stemming', ',', 'une', 'oper', 'de', 'prétrait', 'de', 'text', '.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TwF0qc5KmOvI"
      },
      "source": [
        "## SnowballStemmer --> for other space delimited languages\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Lets see how to **detect and translate a language**"
      ],
      "metadata": {
        "id": "jQZcUDcpTLJK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**langdetect** supports 55 languages out of the box (ISO 639-1 codes)\n",
        "\n",
        "https://en.wikipedia.org/wiki/List_of_ISO_639-1_codes"
      ],
      "metadata": {
        "id": "bq1JL2t-TcAF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langdetect"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-FM9LhgEPG1F",
        "outputId": "c886d953-d38c-459c-9286-399eeddd891a"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting langdetect\n",
            "  Downloading langdetect-1.0.9.tar.gz (981 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m981.5/981.5 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from langdetect) (1.16.0)\n",
            "Building wheels for collected packages: langdetect\n",
            "  Building wheel for langdetect (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for langdetect: filename=langdetect-1.0.9-py3-none-any.whl size=993225 sha256=a2273e7a863e72bf31619283e3ea231be3a4945a83604697e9ffbc6e9592493c\n",
            "  Stored in directory: /root/.cache/pip/wheels/95/03/7d/59ea870c70ce4e5a370638b5462a7711ab78fba2f655d05106\n",
            "Successfully built langdetect\n",
            "Installing collected packages: langdetect\n",
            "Successfully installed langdetect-1.0.9\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sSvdkYi6mOvJ",
        "outputId": "f97e373d-4c98-429f-e5b7-a0332170ee9b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from textblob import TextBlob\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "from langdetect import detect\n",
        "text = \"This is achieved in practice during stemming, a text preprocessing operation.\"\n",
        "print(detect(text))\n",
        "\n",
        "en_blob = TextBlob(text)\n",
        "fr_blob = en_blob.translate(from_lang=\"en\", to='fr')\n",
        "print(fr_blob)\n",
        "\n",
        "tokens = fr_blob.words\n",
        "print(tokens)\n",
        "print()\n",
        "\n",
        "stemmer = nltk.SnowballStemmer('french')\n",
        "print([stemmer.stem(t) for t in tokens])"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "en\n",
            "Ceci est réalisé dans la pratique pendant la tige, une opération de prétraitement du texte.\n",
            "['Ceci', 'est', 'réalisé', 'dans', 'la', 'pratique', 'pendant', 'la', 'tige', 'une', 'opération', 'de', 'prétraitement', 'du', 'texte']\n",
            "\n",
            "['cec', 'est', 'réalis', 'dan', 'la', 'pratiqu', 'pend', 'la', 'tig', 'une', 'oper', 'de', 'prétrait', 'du', 'text']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Language Detection and Translation\n",
        "!pip install translate==3.6.1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p9rOvYNiTB6L",
        "outputId": "4215d3b6-3420-4446-89ab-2e1418b93a01"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting translate==3.6.1\n",
            "  Downloading translate-3.6.1-py2.py3-none-any.whl (12 kB)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from translate==3.6.1) (8.1.6)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (from translate==3.6.1) (4.9.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from translate==3.6.1) (2.31.0)\n",
            "Collecting libretranslatepy==2.1.1 (from translate==3.6.1)\n",
            "  Downloading libretranslatepy-2.1.1-py3-none-any.whl (3.2 kB)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->translate==3.6.1) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->translate==3.6.1) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->translate==3.6.1) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->translate==3.6.1) (2023.7.22)\n",
            "Installing collected packages: libretranslatepy, translate\n",
            "Successfully installed libretranslatepy-2.1.1 translate-3.6.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Language Detection and Translation\n",
        "from langdetect import detect\n",
        "text = \"Ceci est réalisé en pratique lors du stemming, une opération de prétraitement de texte\"\n",
        "print(detect(text))\n",
        "\n",
        "from translate import Translator\n",
        "translator = Translator(from_lang = 'fr', to_lang='en')\n",
        "print(translator.translate(text))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yXnBvE_dS5gW",
        "outputId": "69a25b1c-c2b7-449e-ab2f-4bc7785c0ec6"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fr\n",
            "This is achieved in practice during stemming, a text preprocessing operation\n"
          ]
        }
      ]
    }
  ]
}